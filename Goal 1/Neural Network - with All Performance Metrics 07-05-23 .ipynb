{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4764349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb34db",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_csv(\"nba_games.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55794ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "games.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12742c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "games[\"team\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "games[games[\"team\"] == \"GSW\"].sort_values(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfbe8c5",
   "metadata": {},
   "source": [
    "Counts how many games are in each season "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44319d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "games[\"season\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a829c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "games.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6920b4ff",
   "metadata": {},
   "source": [
    "Deleting column that is not needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a6e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "del games[\"mp.1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5246ea95",
   "metadata": {},
   "source": [
    "Converting existing column to a date time then overiding the existing column with the date time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a60ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "games[\"date\"] = pd.to_datetime(games[\"date\"], format=\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e0f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41adeb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "games.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb10772",
   "metadata": {},
   "source": [
    "Creating predictors for machine learning \n",
    "home says wheteher the team played at a home game or an away game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1f64ff",
   "metadata": {},
   "source": [
    "concatenates the home category in the table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff744c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "games [\"venue_code\"] = games[\"home\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a85962",
   "metadata": {},
   "source": [
    "This creates the code for each opponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "games [\"opp_code\"] = games[\"team_opp\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c7c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "games [\"day_code\"] = games [\"date\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd54daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0593d10",
   "metadata": {},
   "source": [
    "The following code sets up a target to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8963bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "games[\"target\"] = (games[\"won\"] == True).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8cd9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27e681",
   "metadata": {},
   "source": [
    "# Training our neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ca7ee9",
   "metadata": {},
   "source": [
    "Scaling data having vector X as [0], or standardise to have mean 0 and variance 1(ask about this)\n",
    "StandardScaler is used for standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72179c93",
   "metadata": {},
   "source": [
    "Multi-layer Perceptron (MLP) is a supervised learning algorithm that learns a function \n",
    " by training on a dataset, where \n",
    " is the number of dimensions for input and \n",
    " is the number of dimensions for output. Given a set of features \n",
    " and a target \n",
    ", it can learn a non-linear function approximator for either classification or regression. It is different from logistic regression, in that between the input and the output layer, there can be one or more non-linear layers, called hidden layers. Figure 1 shows a one hidden layer MLP with scalar output.\n",
    "Reference: https://scikit-learn.org/stable/modules/neural_networks_supervised.html#tips-on-practical-use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045067a",
   "metadata": {},
   "source": [
    "This Class MLPClassifier implements a multi-layer perceptron (MLP) algorithm that trains using backpropagation(taking the error rate of a forward propagation and feeding this loss backwards through the neural network layer to fine-tune the weights, key to neural net training)\n",
    "Reference: https://builtin.com/machine-learning/backpropagation-neural-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de136b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a425f568",
   "metadata": {},
   "source": [
    "MLP trains on two arrays: array X of size (n_samples, n_features), which holds the training samples represented as floating point feature vectors; and array y of size (n_samples,), which holds the target values (class labels) for the training samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c83721",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0186b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"venue_code\",\"opp_code\",\"day_code\"]\n",
    "X_train = games[games[\"date\"]<'2020-10-11']\n",
    "y_train = games[games[\"date\"]<'2020-10-11']\n",
    "X_test = games[games[\"date\"]>'2020-10-11']\n",
    "y_test = games[games[\"date\"]>'2020-10-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff04771",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train[predictors], y_train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test[predictors])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf47a6",
   "metadata": {},
   "source": [
    "# Performance metrics for our neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff10172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94e5dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(X_test[\"target\"], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b301b4a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c3797",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.DataFrame(dict(actual=X_test[\"target\"], prediction=preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9642b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index= combined[\"actual\"],columns=combined[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6461a30f",
   "metadata": {},
   "source": [
    "470 times the model was correct, 320 times the model was wrong \n",
    "401 times the model was correct, 389 times the model was wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a23558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(X_test[\"target\"], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3b932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(X_test[\"target\"], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9275ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(X_test[\"target\"], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd685188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(X_test[\"target\"], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matri\n",
    "confusion_matrix(X_test[\"target\"], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755085d8",
   "metadata": {},
   "source": [
    "# Improvement of our neural network model with rolling averages\n",
    "\n",
    "Improving the precison with rolling averages- by splitting the data set up in teams\n",
    "This groups the data set into team statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d1a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_games = games.groupby(\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7968375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = grouped_games.get_group(\"GSW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bbd3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a2a0ea",
   "metadata": {},
   "source": [
    "The games of GSW (Golden State Warriors)if the prediction is on the fourth game the model should look at the previous three games to help make better predictions. For example if the team is on a losing streak or a winning streak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66f11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_averages(group, cols, new_cols):\n",
    "    group = group.sort_values(\"date\")\n",
    "    #closed = ''left' only have the rolling averages of the previous weeks not the week we are trying to calculate for\n",
    "    rolling_stats = group[cols].rolling(3,closed='left').mean()\n",
    "    group[new_cols] = rolling_stats\n",
    "    #removes all of the rows that have missing values \n",
    "    group = group.dropna(subset= new_cols)\n",
    "    return group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f8a5b7",
   "metadata": {},
   "source": [
    "Using the same roling averages as the ones used for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99dfde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"fg\",\"3p\",\"ft\",\"ast\",\"stl\",\"blk\",\"tov\", \"pts\"]\n",
    "new_cols = [f\"{c}_rolling\" for c in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a8faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cff45b",
   "metadata": {},
   "source": [
    "These new columns are just for the LAL games "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_averages(group, cols, new_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15ad95f",
   "metadata": {},
   "source": [
    "After getting the original nba_games data Frame and grouped by teams which creates one data frame for each team in the data. Then the lambda function was applied to compute the rolling averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d4a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_rolling = games.groupby(\"team\").apply(lambda x:rolling_averages(x, cols, new_cols)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b65dffc",
   "metadata": {},
   "source": [
    "Rolling averages is applied to the entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1c1bb8",
   "metadata": {},
   "source": [
    "Dropping the team name as a seperate level in the pandas index. for a multi level index you would need to use two values to access each row which was not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_rolling = games_rolling.droplevel('team')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39079537",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_rolling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff30eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_rolling.index = range(games_rolling.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2793894",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58174def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(data,predictors):\n",
    "    X_train = data[data[\"date\"]<'2022-01-01']\n",
    "    y_test = data[data[\"date\"]>'2022-01-01']\n",
    "    clf.fit(X_train[predictors], X_train[\"target\"])\n",
    "    preds = clf.predict(y_test[predictors])\n",
    "    combined = pd.DataFrame(dict(actual=y_test[\"target\"], predicted=preds), index=y_test.index)\n",
    "    precision = precision_score(y_test[\"target\"], preds)\n",
    "    return combined, precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1305412",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined, precision = make_predictions(games_rolling, predictors + new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7b5deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4def1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e0af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merges rows based on index\n",
    "combined = combined.merge(games_rolling[[\"date\", \"team\", \"team_opp\", \"won\"]], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2624a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#information about the team that played their opponent and the result\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f415c7c",
   "metadata": {},
   "source": [
    "Combining home and away predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347bb801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make sure the names of the home and away team are the same \n",
    "#the Dataset already has the same names for home and away teams\n",
    "#for future reference if names need to be normalised\n",
    "class MissingDict(dict):\n",
    "    __missing__ = lambda self, key: key\n",
    "    \n",
    "map_values = {\n",
    "    \n",
    "    \"Golden State Warriors\": \"GSW\",\n",
    "    \"Lakers\": \"LAL\",\n",
    "    \"Boston Celtics\": \"BOS\"\n",
    "    \n",
    "}\n",
    "mapping = MissingDict(**map_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping[\"Golden State Warriors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f11923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"new_team\"] = combined[\"team\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d209159",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0f41db",
   "metadata": {},
   "source": [
    "This makes sure that the predictions are the same on both sides "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f27fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = combined.merge(combined, left_on=[\"date\",\"new_team\"], right_on=[\"date\",\"team_opp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd0bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b02010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def show_missing(games):\n",
    " #   \"\"\"Return a Pandas dataframe describing the contents of a source dataframe including missing values.\"\"\"\n",
    "    \n",
    "  #  variables = []\n",
    "   # dtypes = []\n",
    "    #count = []\n",
    "#    unique = []\n",
    "#    missing = []\n",
    " #   pc_missing = []\n",
    "    \n",
    "  #  for item in games.columns:\n",
    "   #     variables.append(item)\n",
    "    #    dtypes.append(games[item].dtype)\n",
    "     #   count.append(len(games[item]))\n",
    "      #  unique.append(len(games[item].unique()))\n",
    "       # missing.append(games[item].isna().sum())\n",
    "        #pc_missing.append(round((games[item].isna().sum() / len(games[item])) * 100, 2))\n",
    "\n",
    "#    output = pd.DataFrame({\n",
    " #       'variable': variables, \n",
    "  #      'dtype': dtypes,\n",
    "   #     'count': count,\n",
    "    #    'unique': unique,\n",
    "     #   'missing': missing, \n",
    "      #  'pc_missing': pc_missing\n",
    "    #})    \n",
    "        \n",
    "    #return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0318f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_missing(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = pd.isnull(games)\n",
    "nulls = nulls.sum()\n",
    "nulls = nulls[nulls > 0]\n",
    "nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9524c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1666575",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[(merged[\"prediction_x\"] == 1) & (merged[\"prediction_y\"] == 0)][\"actual_x\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262101ad",
   "metadata": {},
   "source": [
    "The accuracy is 76.5% from merging both sides of the match together however manyrows were unable to be recovered to get an accuracy on all of the data frames rows.\n",
    "Using more seasons could improve accuracy\n",
    "Using more columns in the data frame can improve accuracy \n",
    "Look at both current team and opponent team records for the season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined, accuracy = make_predictions(games_rolling, predictors + new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d05a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(data,predictors):\n",
    "    X_train = data[data[\"date\"]<'2022-01-01']\n",
    "    y_test = data[data[\"date\"]>'2022-01-01']\n",
    "    clf.fit(X_train[predictors], X_train[\"target\"])\n",
    "    preds = clf.predict(y_test[predictors])\n",
    "    combined = pd.DataFrame(dict(actual=y_test[\"target\"], predicted=preds), index=y_test.index)\n",
    "    accuracy = accuracy_score(y_test[\"target\"], preds)\n",
    "    return combined, accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b436a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged, accuracy = make_predictions(games_rolling, predictors + new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2009d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b691000d",
   "metadata": {},
   "source": [
    "#### 55% accuracy with rolling averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06006ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
